{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4be2e6fa-2187-4617-8433-0db4fb0c099c",
   "metadata": {},
   "source": [
    "# LangChain 核心模块学习：Model I/O\n",
    "\n",
    "`Model I/O` 是 LangChain 为开发者提供的一套面向 LLM 的标准化模型接口，包括模型输入（Prompts）、模型输出（Output Parsers）和模型本身（Models）。\n",
    "\n",
    "- Prompts：模板化、动态选择和管理模型输入\n",
    "- Models：以通用接口调用语言模型\n",
    "- Output Parser：从模型输出中提取信息，并规范化内容\n",
    "\n",
    "![](images/model_io.jpeg)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e64b01e-f5ad-4614-b0c3-a140f6bb575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\python311\\lib\\site-packages (0.0.262)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python311\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python311\\lib\\site-packages (from langchain) (2.0.19)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\python311\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\python311\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in c:\\python311\\lib\\site-packages (from langchain) (0.0.22)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\python311\\lib\\site-packages (from langchain) (2.8.5)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\python311\\lib\\site-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\python311\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\python311\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python311\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\python311\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\python311\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "# 安装最新版本的 LangChain Python SDK（https://github.com/langchain-ai/langchain）\n",
    "!pip install -U langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a2474-0b69-4830-85cd-3715c22df304",
   "metadata": {},
   "source": [
    "## 模型输入 Prompts\n",
    "\n",
    "一个语言模型的提示是用户提供的一组指令或输入，用于引导模型的响应，帮助它理解上下文并生成相关和连贯的基于语言的输出，例如回答问题、完成句子或进行对话。\n",
    "\n",
    "\n",
    "- 提示模板（Prompt Templates）：参数化的模型输入\n",
    "- 示例选择器（Example Selectors）：动态选择要包含在提示中的示例\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14f4cf-8e30-47ab-b8b1-d58a90b5b1c1",
   "metadata": {},
   "source": [
    "## 提示模板 Prompt Templates\n",
    "\n",
    "**Prompt Templates 提供了一种预定义、动态注入、模型无关和参数化的提示词生成方式，以便在不同的语言模型之间重用模板。**\n",
    "\n",
    "一个模板可能包括指令、少量示例以及适用于特定任务的具体背景和问题。\n",
    "\n",
    "通常，提示要么是一个字符串（LLMs），要么是一组聊天消息（Chat Model）。\n",
    "\n",
    "\n",
    "类继承关系:\n",
    "\n",
    "```\n",
    "BasePromptTemplate --> PipelinePromptTemplate\n",
    "                       StringPromptTemplate --> PromptTemplate\n",
    "                                                FewShotPromptTemplate\n",
    "                                                FewShotPromptWithTemplates\n",
    "                       BaseChatPromptTemplate --> AutoGPTPrompt\n",
    "                                                  ChatPromptTemplate --> AgentScratchPadChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "BaseMessagePromptTemplate --> MessagesPlaceholder\n",
    "                              BaseStringMessagePromptTemplate --> ChatMessagePromptTemplate\n",
    "                                                                  HumanMessagePromptTemplate\n",
    "                                                                  AIMessagePromptTemplate\n",
    "                                                                  SystemMessagePromptTemplate\n",
    "\n",
    "PromptValue --> StringPromptValue\n",
    "                ChatPromptValue\n",
    "```\n",
    "\n",
    "\n",
    "**代码实现：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/prompts**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40c4a43-530b-4ee1-af40-e2c90c0c8c66",
   "metadata": {},
   "source": [
    "### 使用 PromptTemplate 类生成提升词\n",
    "\n",
    "**通常，`PromptTemplate` 类的实例，使用Python的`str.format`语法生成模板化提示；也可以使用其他模板语法（例如jinja2）。**\n",
    "\n",
    "#### 使用 from_template 方法实例化 PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9300dcbb-204b-4f14-b06e-306894177eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Azure Open AI settings\n",
    "\n",
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "#OS level settings\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-03-15-preview\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://cms-oai.openai.azure.com/\"\n",
    "deployment_name = \"chatbamboo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d681566-cde1-4ae5-8cd7-f53cf59c3e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a funny joke about chickens.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from langchain import PromptTemplate\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "#prompt_template = PromptTemplate.from_template(\n",
    "prompt_template = PromptTemplate.from_template(    \n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "# 使用 format 生成提示\n",
    "prompt = prompt_template.format(adjective=\"funny\", content=\"chickens\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09e2b7f-d1e1-4cc3-bf9b-22de07df5513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['adjective', 'content'] output_parser=None partial_variables={} template='Tell me a {adjective} joke about {content}.' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c329075-0a6a-4d17-9cc3-081be37f7917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a joke\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a joke\"\n",
    ")\n",
    "# 生成提示\n",
    "prompt = prompt_template.format()\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13696d97-9c8f-4530-92ec-a9cdf2012bf7",
   "metadata": {},
   "source": [
    "#### 使用构造函数（Initializer）实例化 PromptTemplate\n",
    "\n",
    "使用构造函数实例化 `prompt_template` 时必须传入参数：`input_variables` 和 `template`。\n",
    "\n",
    "在生成提示过程中，会检查输入变量与模板字符串中的变量是否匹配，如果不匹配，则会引发异常；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10e7686a-dcca-4410-9263-6e941bee9c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\",\"content\"],\n",
    "    template=\"Tell me a {adjective} joke about {content}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49767dc4-2057-4fee-8fb0-24436194c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"],\n",
    "    template=\"Tell me a {adjective} joke about {content}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "516cee06-9673-4c9d-9499-1355034ad82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['adjective', 'content'] output_parser=None partial_variables={} template='Tell me a {adjective} joke about {content}.' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "print(valid_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c7a677-4ae8-4c81-829c-49fd597c45bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_prompt.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb638c-7033-4cf2-9354-6481170c9892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "754269b1-a2a7-487e-85b3-3be916be581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"讲{num}个给程序员听得笑话\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc708563-8556-466d-9ea5-9f41c8e6a7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: 讲2个给程序员听得笑话\n",
      "result: \n",
      "\n",
      "1、程序员就像是个工具人，你可以让他写程序，你也可以让他做别的事，比如敲钉子。\n",
      "\n",
      "2、程序员的脑子就像是个计算机，只要输入合适的代码，程序员就会自动输出正确的答案。\n",
      "\n",
      "3、一个程序员去面试，面试官问：“你知道C++吗？”程序员回答：“当然知道，我在上学的时候学过。”\n",
      "\n",
      "4、程序员就是个懒人，只要有了一段代码，他就会拼命地复制粘贴。\n",
      "\n",
      "5、有了程序员，就等于有了一个不用休息的机器。\n",
      "\n",
      "6、程序员的工作就像是数学考试，只要你不会，任何人都不会。\n",
      "\n",
      "7、程序员就像是个机器，只要输入对了代码，就会自动输出正确的结果。\n",
      "\n",
      "8、程序员的智商能力就像是个火车头，只要有了正确的路线，火车头就会自动开到目的地。\n",
      "\n",
      "9、一个程序员去面试，面试官问：“你知道C++吗？”程序员回答：“当然知道，我的电脑上装了好几个版本呢。”\n",
      "\n",
      "10、程序员会用代码给人生赋值，只要你想，他就能做到。\"\"\"\n",
      "print(\"\".join(list(map(lambda x: x+\"。\" if x[-1] not in ['。','！','？','，'] else x,text.split('。')))))<|im_sep|>\n"
     ]
    }
   ],
   "source": [
    "#from langchain.llms import OpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "#llm = OpenAI(model_name=\"text-davinci-003\", max_tokens=1000)\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name = deployment_name,\n",
    "    model_name=\"text-davinci-003\", max_tokens=1000)\n",
    "\n",
    "prompt = prompt_template.format(num=2)\n",
    "print(f\"prompt: {prompt}\")\n",
    "\n",
    "result = llm(prompt)\n",
    "print(f\"result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c6dd3ea-084a-4426-bba0-2676d42842c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "，你都笑了吗？\n",
      "\n",
      "第一个：\n",
      "\n",
      "程序员不是一个重复写代码的人，他们是一个重复解决问题的人。第二个：\n",
      "\n",
      "两个程序员是夫妻，他们有一个孩子，为什么他们不给孩子取名叫“CODE”？因为名字太短了，不够3个字符。\n",
      "\n",
      "第三个：\n",
      "\n",
      "这个程序员告诉他的儿子：“不要沉迷于你的代码，你必须学会沉迷于你的生活，这样你的代码才会更好。”\n",
      "\n",
      "第四个：\n",
      "\n",
      "计算机科学家的工作就是开发出足够好的代码，使他们的工作不再需要计算机科学家。\n",
      "\n",
      "第五个：\n",
      "\n",
      "有三种人，一种懂得二进制，一种不懂得二进制。\n",
      "\n",
      "第六个：\n",
      "\n",
      "程序员每天都尝试着解决问题，这也是他们每天的工作。\n",
      "\n",
      "第七个：\n",
      "\n",
      "程序员的一个朋友问他：“你知道如何让一只猫看起来像一只狗吗？”程序员回答：“为什么要让猫看起来像狗呢？”\n",
      "\n",
      "第八个：\n",
      "\n",
      "程序员的一位朋友告诉他：“我有一个问题，我想用一块石头打破我的电脑。”程序员回答：“我可以帮你解决这个问题。”\n",
      "\n",
      "第九个：\n",
      "\n",
      "程序员的一位朋友告诉他：“我不明白为什么计算机系统总是崩溃。”程序员回答：“那是因为你没有足够的RAM。”\n",
      "\n",
      "第十个：\n",
      "\n",
      "当程序员遇到了一个新的问题时，他们会尝试着去解决它，而不是去抱怨这个问题。\n",
      "\n",
      "第十一个：\n",
      "\n",
      "程序员不是一个单纯的工作人员，他们是一个不断学习和成长的人。\n",
      "\n",
      "第十二个：\n",
      "\n",
      "程序员不会告诉你他们不知道如何解决一个问题，他们只会告诉你他们正在努力寻找答案。\n",
      "\n",
      "第十三个：\n",
      "\n",
      "程序员不断学习和成长，这也是他们成功的原因之一。\n",
      "\n",
      "第十四个：\n",
      "\n",
      "程序员的最终目标是使程序变得更加高效和可靠。\n",
      "\n",
      "第十五个：\n",
      "\n",
      "程序员是一个非常有耐心的人，他们可以花很长时间来解决一个问题。\n",
      "\n",
      "第十六个：\n",
      "\n",
      "程序员的工作就是将想法转化为代码。\n",
      "\n",
      "第十七个：\n",
      "\n",
      "程序员的一个朋友问他：“你知道如何用一张纸打印出一份文件吗？”程序员回答：“我只知道如何用打印机打印。”\n",
      "\n",
      "第十八个：\n",
      "\n",
      "程序员不仅仅是一个写代码的人，他们也是一个解决问题的人。\n",
      "\n",
      "第十九个：\n",
      "\n",
      "程序员不断学习和成长，这也是他们获得更多机会的原因之一。\n",
      "\n",
      "第二十个：\n",
      "\n",
      "程序员不仅仅是一个工作人员，他们也是一个不断学习和成长的人。\n",
      "\n",
      "第二十一个：\n",
      "\n",
      "程序员的工作就是让计算机做更多的工作，让人们做更少的工作。\n",
      "\n",
      "第二十二个：\n",
      "\n",
      "程序员不断学习和成长，这也是他们越来越成功的原因之一。\n",
      "\n",
      "第二十三个：\n",
      "\n",
      "程序员的一个朋友问他：“你知道如何让计算机变得更快吗？”程序员回答：“我不知道，但我会努力去学习。”\n",
      "\n",
      "第二十四个：\n",
      "\n",
      "程序员不断学习和成长，这也是他们不断进步的原因之一。\n",
      "\n",
      "第二十五个：\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt_template.format(num=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890a0b3-c5af-4d0e-b1a1-3439f3199edc",
   "metadata": {},
   "source": [
    "#### 使用 jinja2 生成模板化提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e98620d-3462-4a7d-b9ef-1a9a0fd1f496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jinja2_template = \"Tell me a {{ adjective }} joke about {{ content }}\"\n",
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "\n",
    "prompt.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b707a3f-c6c1-4aa1-9ad2-4067c0430e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['adjective', 'content'] output_parser=None partial_variables={} template='Tell me a {{ adjective }} joke about {{ content }}' template_format='jinja2' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495b7cc-5c5c-4635-95b0-e46f8f48cb5e",
   "metadata": {},
   "source": [
    "#### 使用 f-string 生成模板化提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0d98afa-0e41-4ca1-a799-8882acf26d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fstring_template = \"\"\"Tell me a {adjective} joke about {content}\"\"\"\n",
    "prompt = PromptTemplate.from_template(fstring_template)\n",
    "\n",
    "prompt.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c08d8-14ee-459e-9a5c-f0d659d08d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b48d41-608c-46e4-ac05-882b05cbfec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c34c3078-3ece-4708-8bf8-cdc02968ea70",
   "metadata": {},
   "source": [
    "#### 实测：生成多种编程语言版本的快速排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c73de848-8091-4ebd-9127-ea33582bad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_prompt_template = PromptTemplate.from_template(\n",
    "    \"生成可执行的快速排序 {programming_language} 代码\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3c2ee81-80aa-4ad9-b936-8c2e1b2ba27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "，并返回字符串形式的代码。\n",
      "\n",
      "样例\n",
      "\n",
      "convertToPython([3,2,1])\n",
      "返回：\n",
      "'import random\\n\\n\\ndef quickSort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    index = random.randint(0, len(arr)-1)\\n    pivot = arr[index]\\n    left = []\\n    right = []\\n    for i in range(len(arr)):\\n        if i == index:\\n            continue\\n        elif arr[i] <= pivot:\\n            left.append(arr[i])\\n        else:\\n            right.append(arr[i])\\n\\n    return quickSort(left) + [pivot] + quickSort(right)'\n",
      "\n",
      "注意事项\n",
      "\n",
      "- 你可以假设输入的数组中没有重复元素。\n",
      "- 你生成的代码必须包含一个 quickSort(arr) 方法，其中 arr 是待排序的数组，该方法必须返回一个数组。quickSort(arr) 方法的实现应该与上面的描述相同。\n",
      "- 你不能使用 eval()，exec()，import。\"\"\"\n",
      "\n",
      "\n",
      "def convertToPython(nums):\n",
      "    res = 'import random\\n\\n'\n",
      "    res += 'def quickSort(arr):\\n'\n",
      "    res += '    if len(arr) <= 1:\\n        return arr\\n'\n",
      "    res += '    index = random.randint(0, len(arr)-1)\\n'\n",
      "    res += '    pivot = arr[index]\\n'\n",
      "    res += '    left = []\\n'\n",
      "    res += '    right = []\\n'\n",
      "    res += '    for i in range(len(arr)):\\n'\n",
      "    res += '        if i == index:\\n'\n",
      "    res += '            continue\\n'\n",
      "    res += '        elif arr[i] <= pivot:\\n'\n",
      "    res += '            left.append(arr[i])\\n'\n",
      "    res += '        else:\\n'\n",
      "    res += '            right.append(arr[i])\\n\\n'\n",
      "    res += '    return quickSort(left) + [pivot] + quickSort(right)'\n",
      "    return res\n",
      "\n",
      "\n",
      "print(convertToPython([3, 2, 1]))\n",
      "print(convertToPython([3, 2, 1, 4, 5, 6, 7]))\n",
      "print(convertToPython([1, 1, 1]))\n",
      "print(convertToPython([1]))\n",
      "print(convertToPython([]))<|im_sep|>\n"
     ]
    }
   ],
   "source": [
    "print(llm(sort_prompt_template.format(programming_language=\"python\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba3b370e-a647-4913-b4a0-c33d4dd11e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "，如下所示：\n",
      "\n",
      "public class QuickSort {\n",
      "    // 快速排序\n",
      "    public static void quickSort(int[] arr, int left, int right) {\n",
      "        if (left >= right) {\n",
      "            return;\n",
      "        }\n",
      "        int i = left - 1, j = right + 1, pivot = arr[left + right >> 1];\n",
      "        while (i < j) {\n",
      "            do i++; while (arr[i] < pivot);\n",
      "            do j--; while (arr[j] > pivot);\n",
      "            if (i < j) {\n",
      "                swap(arr, i, j);\n",
      "            }\n",
      "        }\n",
      "        quickSort(arr, left, j);\n",
      "        quickSort(arr, j + 1, right);\n",
      "    }\n",
      "    // 交换数组中的两个元素\n",
      "    public static void swap(int[] arr, int i, int j) {\n",
      "        int temp = arr[i];\n",
      "        arr[i] = arr[j];\n",
      "        arr[j] = temp;\n",
      "    }\n",
      "}\n",
      "\n",
      "Java 代码已经准备好了，我们可以在本地运行和调试。接下来，我们需要编写一个自动化脚本，来编译并运行我们的测试数据。\n",
      "\n",
      "- 在项目根目录下创建一个名为 test.sh 的文件；\n",
      "- 将下面的代码复制到 test.sh 文件中：\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "# 该脚本的作用是测试快速排序算法\n",
      "# Git 仓库地址：https://github.com/wangchuande/blog-code/tree/main/quick-sort\n",
      "\n",
      "# ==================== 全局配置 ====================\n",
      "# 测试数据的大小\n",
      "dataSize=10000000\n",
      "# 测试次数\n",
      "testCount=5\n",
      "\n",
      "# ==================== 编译 Java 代码 ====================\n",
      "echo \"Compiling Java code...\"\n",
      "javac QuickSort.java\n",
      "\n",
      "# ==================== 运行 Java 代码 ====================\n",
      "echo \"Running Java code...\"\n",
      "for ((i=1; i<=testCount; i++)){\n",
      "    echo \"Test $i: \"\n",
      "    # 生成测试数据\n",
      "    echo \"Generating test data...\"\n",
      "    ./generate-random-data $dataSize > input.txt\n",
      "    # 记录开始时间\n",
      "    start=$(date +%s)\n",
      "    # 执行快速排序程序\n",
      "    java QuickSort < input.txt > /dev/null\n",
      "    # 记录结束时间\n",
      "    end=$(date +%s)\n",
      "    # 计算用时\n",
      "    cost=$(( end - start ))\n",
      "    echo \"Time elapsed: $cost s\"\n",
      "}\n",
      "\n",
      "- 保存并退出 test.sh 文件。\n",
      "- 接下来，需要在项目根目录下创建一个名为 generate-random-data 的文件，用来生成随机的测试数据。将下面的代码复制到 generate-random-data 文件中：\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "# 该脚本的作用是生成随机的测试数据\n",
      "# Git 仓库地址：https://github.com/wangchuande/blog-code/tree/main/quick-sort\n",
      "\n",
      "# ==================== 全局配置 ====================\n",
      "# 测试数据的大小\n",
      "dataSize=10000000\n",
      "# 随机数的范围\n",
      "range=10000000\n",
      "\n",
      "# ==================== 生成测试数据 ====================\n",
      "# 生成随机数\n",
      "echo \"Generating random numbers...\"\n",
      "shuf -i 1-$range -n $dataSize | tr '\\n' ' ' > input.txt\n",
      "\n",
      "- 保存并退出 generate-random-data 文件。\n",
      "- 接下来，需要给这两个文件赋予可执行权限，执行下面的命令：\n",
      "\n",
      "chmod +x test.sh generate-random-data\n",
      "\n",
      "- 最后，执行下面的命令来测试我们的快速排序算法：\n",
      "\n",
      "./test.sh\n",
      "\n",
      "测试结果\n",
      "\n",
      "最后，我们来看下测试的结果，测试数据的大小为 1000 万，测试次数为 5 次，测试结果如下所示：\n",
      "\n",
      "Test 1: \n",
      "Generating test data...\n",
      "Time elapsed: 5 s\n",
      "Test 2: \n",
      "Generating test data...\n",
      "Time elapsed: 3 s\n",
      "Test 3: \n",
      "Generating test data...\n",
      "Time elapsed: 3 s\n",
      "Test 4: \n",
      "Generating test data...\n",
      "Time elapsed: 3 s\n",
      "Test 5: \n",
      "Generating test data...\n",
      "Time elapsed: 3 s\n",
      "\n",
      "我们可以看到，平均每次测试的时间在 3 ~ 5 秒之间，这个速度已经非常快了，快速排序算法已经足以应付绝大部分的排序问题了。\n",
      "\n",
      "上面的测试仅仅是基于随机数据\n"
     ]
    }
   ],
   "source": [
    "print(llm(sort_prompt_template.format(programming_language=\"java\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ef61ce-af9f-40d6-970e-cdacc4d4736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "，以便在最终的 C++ 代码中直接调用。\n",
      "\n",
      "我们将分别从这三个方面来讲解使用 TLE 信息的方法。\n",
      "\n",
      "二分答案\n",
      "\n",
      "二分答案是一种常用的优化方法，它可以将一个 $O(N^2)$ 或者 $O(N^3)$ 的算法优化到 $O(N \\log W)$（其中 $W$ 表示答案范围）。对于 TLE 的问题，一般来说二分答案都是一个不错的选择。\n",
      "\n",
      "这里以 P3812 [IOI2017] Sorting 为例，该题要求我们将一个 $N$ 个数的序列通过交换相邻元素的方式排列成一个有序的序列。其中，交换两个相邻元素的代价为这两个元素的下标之差。\n",
      "\n",
      "我们不难想到一个 $O(N^2)$ 级别的贪心算法：每次找到当前乱序部分中最大的元素，然后将它向前交换直到它的位置是当前乱序部分中的最左侧。我们可以写出下面这样的代码：\n",
      "\n",
      "for (int i = 1; i <= n; ++i) pos[a[i]] = i;\n",
      "int ans = 0;\n",
      "for (int i = n; i > 1; --i) {\n",
      "    int mx = 0;\n",
      "    for (int j = 1; j <= i; ++j)\n",
      "        if (a[j] > a[mx]) mx = j;\n",
      "    ans += i - mx;\n",
      "    for (int j = mx; j < i; ++j) swap(a[j], a[j + 1]), swap(pos[a[j]], pos[a[j + 1]]);\n",
      "}\n",
      "\n",
      "然而，这个代码的复杂度是 $O(N^2)$，很容易被卡掉。我们考虑使用二分答案来优化这个算法。\n",
      "\n",
      "我们设 $r$ 表示当前的答案，即当前乱序部分中的两个元素之间的距离不超过 $r$，我们的目标是求出答案 $r$。对于每个 $r$，我们可以使用上面的贪心算法检查答案是否不小于 $r$。具体地，我们可以在跑贪心的时候，每当一个元素的位置不在合法范围内时，就将答案加上当前的 $r$。如果答案达到了 $r$，那么当前的 $r$ 就不可能成为答案，我们需要退出检查。\n",
      "\n",
      "检查的过程复杂度是 $O(N)$，因此对于一个特定的 $r$，总复杂度是 $O(N)$。因此，我们可以使用二分答案来求出答案。由于答案的范围是 $[0, N]$，因此总复杂度是 $O(N \\log N)$。\n",
      "\n",
      "具体的代码实现可以参考下面的代码：\n",
      "\n",
      "for (int L = 0, R = n; L <= R;) {\n",
      "    int mid = (L + R) >> 1;\n",
      "    bool flag = true;\n",
      "    for (int i = n; i > 1; --i) {\n",
      "        int mx = 0;\n",
      "        for (int j = 1; j <= i; ++j)\n",
      "            if (a[j] > a[mx]) mx = j;\n",
      "        if (i - mx > mid) {\n",
      "            flag = false;\n",
      "            break;\n",
      "        }\n",
      "        ans += i - mx;\n",
      "        if (ans > mid) {\n",
      "            flag = false;\n",
      "            break;\n",
      "        }\n",
      "        for (int j = mx; j < i; ++j)\n",
      "            swap(a[j], a[j + 1]), swap(pos[a[j]], pos[a[j + 1]]);\n",
      "    }\n",
      "    if (flag) R = mid - 1;\n",
      "    else L = mid + 1;\n",
      "}\n",
      "\n",
      "注意，在这里我们使用了一个小技巧，即不记录 $a$ 数组中元素的位置，而是记录它们的下标。这样可以使代码更简洁，同时也不会影响时间复\n"
     ]
    }
   ],
   "source": [
    "print(llm(sort_prompt_template.format(programming_language=\"C++\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510954a1-2c16-414c-ada1-af9d439d43be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "621af4b1-0337-428a-bc88-17f1ff1f876e",
   "metadata": {},
   "source": [
    "## 使用 ChatPromptTemplate 类生成适用于聊天模型的聊天记录\n",
    "\n",
    "**`ChatPromptTemplate` 类的实例，使用`format_messages`方法生成适用于聊天模型的提示。**\n",
    "\n",
    "### 使用 from_messages 方法实例化 ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "875c8534-7317-4111-9658-80a926458168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "# 生成提示\n",
    "messages = template.format_messages(\n",
    "    name=\"Bob\",\n",
    "    user_input=\"What is your name?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ceb1c89b-c71a-4e7c-bf81-2f2a5ddcf80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, example=False), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, example=False), HumanMessage(content='What is your name?', additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a99257dd-3dad-48bd-9c75-1ab9348179ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI bot. Your name is Bob.\n",
      "What is your name?\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)\n",
    "print(messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "feba7a9c-d3c3-418c-8ee7-b033c3da1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.chat_models import ChatOpenAI\n",
    "#chat_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", max_tokens=1000)\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "chat_model = AzureChatOpenAI(\n",
    "    deployment_name=deployment_name,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40342d2c-43f1-4bce-ae06-0dda2fdea608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"My name is Bob, I'm an AI bot designed to assist you with any questions or tasks you may have. How can I assist you today?\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a095b3-3e0d-4a05-9cea-620a6155be22",
   "metadata": {},
   "source": [
    "### 摘要总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe696871-bc41-48f3-b41b-43bb9f9ddcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你将获得关于同一主题的{num}篇文章（用-----------标签分隔）。首先总结每篇文章的论点。然后指出哪篇文章提出了更好的论点，并解释原因。\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c1d1c65-fd90-48d0-88eb-3eb1cade5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = summary_template.format_messages(\n",
    "    num=3,\n",
    "    user_input='''1. [PHP是世界上最好的语言]\n",
    "PHP是世界上最好的情感派编程语言，无需逻辑和算法，只要情绪。它能被蛰伏在冰箱里的PHP大神轻易驾驭，会话结束后的感叹号也能传达对代码的热情。写PHP就像是在做披萨，不需要想那么多，只需把配料全部扔进一个碗，然后放到服务器上，热乎乎出炉的网页就好了。\n",
    "-----------\n",
    "2. [Python是世界上最好的语言]\n",
    "Python是世界上最好的拜金主义者语言。它坚信：美丽就是力量，简洁就是灵魂。Python就像是那个永远在你皱眉的那一刻扔给你言情小说的好友。只有Python，你才能够在两行代码之间感受到飘逸的花香和清新的微风。记住，这世上只有一种语言可以使用空格来领导全世界的进步，那就是Python。\n",
    "-----------\n",
    "3. [Java是世界上最好的语言]\n",
    "Java是世界上最好的德育课编程语言，它始终坚守了严谨、安全的编程信条。Java就像一个严格的老师，他不会对你怀柔，不会让你偷懒，也不会让你走捷径，但他教会你规范和自律。Java就像是那个喝咖啡也算加班费的上司，拥有对邪恶的深度厌恶和对善良的深度拥护。\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0042c49-3a75-4098-9037-eb54f288b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [PHP是世界上最好的语言]\n",
      "PHP是世界上最好的情感派编程语言，无需逻辑和算法，只要情绪。它能被蛰伏在冰箱里的PHP大神轻易驾驭，会话结束后的感叹号也能传达对代码的热情。写PHP就像是在做披萨，不需要想那么多，只需把配料全部扔进一个碗，然后放到服务器上，热乎乎出炉的网页就好了。\n",
      "-----------\n",
      "2. [Python是世界上最好的语言]\n",
      "Python是世界上最好的拜金主义者语言。它坚信：美丽就是力量，简洁就是灵魂。Python就像是那个永远在你皱眉的那一刻扔给你言情小说的好友。只有Python，你才能够在两行代码之间感受到飘逸的花香和清新的微风。记住，这世上只有一种语言可以使用空格来领导全世界的进步，那就是Python。\n",
      "-----------\n",
      "3. [Java是世界上最好的语言]\n",
      "Java是世界上最好的德育课编程语言，它始终坚守了严谨、安全的编程信条。Java就像一个严格的老师，他不会对你怀柔，不会让你偷懒，也不会让你走捷径，但他教会你规范和自律。Java就像是那个喝咖啡也算加班费的上司，拥有对邪恶的深度厌恶和对善良的深度拥护。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fee264c1-941b-42b5-a737-9320eb4f5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result = chat_model(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92ada5fc-bee1-4e66-9f87-7d454491108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一篇文章的论点是PHP是世界上最好的情感派编程语言，无需逻辑和算法，只要情绪。第二篇文章的论点是Python是世界上最好的拜金主义者语言，坚信美丽就是力量，简洁就是灵魂。第三篇文章的论点是Java是世界上最好的德育课编程语言，始终坚守严谨、安全的编程信条。\n",
      "\n",
      "在我看来，第三篇文章提出了更好的论点，原因如下：Java是一种旨在提高软件质量和可维护性的编程语言。它的设计目标是在编程中提供更高的可靠性，使程序员能够编写出更健壮、更安全、更可靠的软件。Java的语法和结构非常严谨，这使得它成为一种非常好的编程语言，尤其适合大型项目。相比之下，PHP和Python更注重代码的灵活性和易用性，但这往往会导致代码的不稳定和难以维护，特别是在大型团队中。因此，我认为第三篇文章提出的论点更加合理和有道理。\n"
     ]
    }
   ],
   "source": [
    "print(chat_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc089de4-84e1-4d50-91e5-6d49ade2cea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你将获得关于同一主题的2篇文章（用-----------标签分隔）。首先总结每篇文章的论点。然后指出哪篇文章提出了更好的论点，并解释原因。', additional_kwargs={}), HumanMessage(content='1.认为“道可道”中的第一个“道”，指的是道理，如仁义礼智之类；“可道”中的“道”，指言说的意思；“常道”，指恒久存在的“道”。因此，所谓“道可道，非常道”，指的是可以言说的道理，不是恒久存在的“道”，恒久存在的“道”不可言说。如苏辙说：“莫非道也。而可道者不可常，惟不可道，而后可常耳。今夫仁义礼智，此道之可道者也。然而仁不可以为义，而礼不可以为智，可道之不可常如此。……而道常不变，不可道之能常如此。”蒋锡昌说：“此道为世人所习称之道，即今人所谓‘道理’也，第一‘道’字应从是解。《广雅·释诂》二：‘道，说也’，第二‘道’字应从是解。‘常’乃真常不易之义，在文法上为区别词。……第三‘道’字即二十五章‘道法自然’之‘道’，……乃老子学说之总名也”。陈鼓应说：“第一个‘道’字是人们习称之道，即今人所谓‘道理’。第二个‘道’字，是指言说的意思。第三个‘道’字，是老子哲学上的专有名词，在本章它意指构成宇宙的实体与动力。……‘常道’之‘常’，为真常、永恒之意。……可以用言词表达的道，就不是常道”。\\n-----------\\n2.认为“道可道”中的第一个“道”，指的是宇宙万物的本原；“可道”中的“道”，指言说的意思；“常道”，指恒久存在的“道”。因此，“道可道，非常道”，指可以言说的“道”，就不是恒久存在的“道”。如张默生说：“‘道’，指宇宙的本体而言。……‘常’，是经常不变的意思。……可以说出来的道，便不是经常不变的道”。董平说：“第一个‘道’字与‘可道’之‘道’，内涵并不相同。第一个‘道’字，是老子所揭示的作为宇宙本根之‘道’；‘可道’之‘道’，则是‘言说’的意思。……这里的大意就是说：凡一切可以言说之‘道’，都不是‘常道’或永恒之‘道’”。汤漳平等说：“第一句中的三个‘道’，第一、三均指形上之‘道’，中间的‘道’作动词，为可言之义。……道可知而可行，但非恒久不变之道”。\\n--------\\n3.认为“道可道”中的第一个“道”，指的是宇宙万物的本原；“可道”中的“道”，指言说的意思；“常道”，则指的是平常人所讲之道、常俗之道。因此，“道可道，非常道”，指“道”是可以言说的，但它不是平常人所谓的道或常俗之道。如李荣说：“道者，虚极之理也。夫论虚极之理，不可以有无分其象，不可以上下格其真。……圣人欲坦兹玄路，开以教门，借圆通之名，目虚极之理，以理可名，称之可道。故曰‘吾不知其名，字之曰道’。非常道者，非是人间常俗之道也。人间常俗之道，贵之以礼义，尚之以浮华，丧身以成名，忘己而徇利。”司马光说：“世俗之谈道者，皆曰道体微妙，不可名言。老子以为不然，曰道亦可言道耳，然非常人之所谓道也。……常人之所谓道者，凝滞于物。”裘锡圭说：“到目前为止，可以说，几乎从战国开始，大家都把‘可道’之‘道’……看成老子所否定的，把‘常道’‘常名’看成老子所肯定的。这种看法其实有它不合理的地方，……‘道’是可以说的。《老子》这个《道经》第一章，开宗明义是要讲他的‘道’。第一个‘道’字，理所应当，也是讲他要讲的‘道’：道是可以言说的。……那么这个‘恒’字应该怎么讲？我认为很简单，‘恒’字在古代作定语用，经常是‘平常’‘恒常’的意思。……‘道’是可以言说的，但是我要讲的这个‘道’，不是‘恒道’，它不是一般人所讲的‘道’。\\n', additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "messages = summary_template.format_messages(\n",
    "    num=2,\n",
    "    user_input='''1.认为“道可道”中的第一个“道”，指的是道理，如仁义礼智之类；“可道”中的“道”，指言说的意思；“常道”，指恒久存在的“道”。因此，所谓“道可道，非常道”，指的是可以言说的道理，不是恒久存在的“道”，恒久存在的“道”不可言说。如苏辙说：“莫非道也。而可道者不可常，惟不可道，而后可常耳。今夫仁义礼智，此道之可道者也。然而仁不可以为义，而礼不可以为智，可道之不可常如此。……而道常不变，不可道之能常如此。”蒋锡昌说：“此道为世人所习称之道，即今人所谓‘道理’也，第一‘道’字应从是解。《广雅·释诂》二：‘道，说也’，第二‘道’字应从是解。‘常’乃真常不易之义，在文法上为区别词。……第三‘道’字即二十五章‘道法自然’之‘道’，……乃老子学说之总名也”。陈鼓应说：“第一个‘道’字是人们习称之道，即今人所谓‘道理’。第二个‘道’字，是指言说的意思。第三个‘道’字，是老子哲学上的专有名词，在本章它意指构成宇宙的实体与动力。……‘常道’之‘常’，为真常、永恒之意。……可以用言词表达的道，就不是常道”。\n",
    "-----------\n",
    "2.认为“道可道”中的第一个“道”，指的是宇宙万物的本原；“可道”中的“道”，指言说的意思；“常道”，指恒久存在的“道”。因此，“道可道，非常道”，指可以言说的“道”，就不是恒久存在的“道”。如张默生说：“‘道’，指宇宙的本体而言。……‘常’，是经常不变的意思。……可以说出来的道，便不是经常不变的道”。董平说：“第一个‘道’字与‘可道’之‘道’，内涵并不相同。第一个‘道’字，是老子所揭示的作为宇宙本根之‘道’；‘可道’之‘道’，则是‘言说’的意思。……这里的大意就是说：凡一切可以言说之‘道’，都不是‘常道’或永恒之‘道’”。汤漳平等说：“第一句中的三个‘道’，第一、三均指形上之‘道’，中间的‘道’作动词，为可言之义。……道可知而可行，但非恒久不变之道”。\n",
    "--------\n",
    "3.认为“道可道”中的第一个“道”，指的是宇宙万物的本原；“可道”中的“道”，指言说的意思；“常道”，则指的是平常人所讲之道、常俗之道。因此，“道可道，非常道”，指“道”是可以言说的，但它不是平常人所谓的道或常俗之道。如李荣说：“道者，虚极之理也。夫论虚极之理，不可以有无分其象，不可以上下格其真。……圣人欲坦兹玄路，开以教门，借圆通之名，目虚极之理，以理可名，称之可道。故曰‘吾不知其名，字之曰道’。非常道者，非是人间常俗之道也。人间常俗之道，贵之以礼义，尚之以浮华，丧身以成名，忘己而徇利。”司马光说：“世俗之谈道者，皆曰道体微妙，不可名言。老子以为不然，曰道亦可言道耳，然非常人之所谓道也。……常人之所谓道者，凝滞于物。”裘锡圭说：“到目前为止，可以说，几乎从战国开始，大家都把‘可道’之‘道’……看成老子所否定的，把‘常道’‘常名’看成老子所肯定的。这种看法其实有它不合理的地方，……‘道’是可以说的。《老子》这个《道经》第一章，开宗明义是要讲他的‘道’。第一个‘道’字，理所应当，也是讲他要讲的‘道’：道是可以言说的。……那么这个‘恒’字应该怎么讲？我认为很简单，‘恒’字在古代作定语用，经常是‘平常’‘恒常’的意思。……‘道’是可以言说的，但是我要讲的这个‘道’，不是‘恒道’，它不是一般人所讲的‘道’。\n",
    "'''\n",
    ")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c048f55c-72f7-463d-af87-9aca561ddf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一篇文章认为，“道可道”中的第一个“道”指的是道理，而“可道”中的“道”指言说的意思，而“常道”则指恒久存在的“道”。第二篇和第三篇文章则认为，“道可道”中的第一个“道”指的是宇宙万物的本原，而“可道”中的“道”仍然指言说的意思，而“常道”则分别指恒久存在的“道”和平常人所讲之道、常俗之道。 \n",
      "\n",
      "在这两篇文章中，第三篇文章提出了更好的论点。首先，该文章对“道”作为宇宙本原进行了深入的解释，而且更加符合老子的思想。其次，该文章还深入探讨了“常道”的概念，将其定义为平常人所讲之道、常俗之道，并且指出老子所讲的“道”并不是这种“常道”。这一点与第二篇文章也有所相似，但是第三篇文章更加详细地解释了这个问题。因此，第三篇文章提出了更好的论点。\n"
     ]
    }
   ],
   "source": [
    "chat_result = chat_model(messages)\n",
    "print(chat_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d7fea-ff97-4c92-a478-f14be0cbd00b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02f6280a-f38d-46f8-a5ff-06f98025f46e",
   "metadata": {},
   "source": [
    "### 使用 FewShotPromptTemplate 类生成 Few-shot Prompt \n",
    "\n",
    "构造 few-shot prompt 的方法通常有两种：\n",
    "- 从示例集（set of examples）中手动选择；\n",
    "- 通过示例选择器（Example Selector）自动选择."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d086861b-b576-446e-bf2f-89544e500c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "\n",
    "examples = [\n",
    "  {\n",
    "    \"question\": \"谁活得更久，穆罕默德·阿里还是艾伦·图灵？\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：穆罕默德·阿里去世时多大了？\n",
    "中间答案：穆罕默德·阿里去世时74岁。\n",
    "追问：艾伦·图灵去世时多大了？\n",
    "中间答案：艾伦·图灵去世时41岁。\n",
    "所以最终答案是：穆罕默德·阿里\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"craigslist的创始人是什么时候出生的？\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：谁是craigslist的创始人？\n",
    "中间答案：Craigslist是由Craig Newmark创办的。\n",
    "追问：Craig Newmark是什么时候出生的？\n",
    "中间答案：Craig Newmark出生于1952年12月6日。\n",
    "所以最终答案是：1952年12月6日\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"乔治·华盛顿的外祖父是谁？\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：谁是乔治·华盛顿的母亲？\n",
    "中间答案：乔治·华盛顿的母亲是Mary Ball Washington。\n",
    "追问：Mary Ball Washington的父亲是谁？\n",
    "中间答案：Mary Ball Washington的父亲是Joseph Ball。\n",
    "所以最终答案是：Joseph Ball\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"《大白鲨》和《皇家赌场》的导演是同一个国家的吗？\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：谁是《大白鲨》的导演？\n",
    "中间答案：《大白鲨》的导演是Steven Spielberg。\n",
    "追问：Steven Spielberg来自哪里？\n",
    "中间答案：美国。\n",
    "追问：谁是《皇家赌场》的导演？\n",
    "中间答案：《皇家赌场》的导演是Martin Campbell。\n",
    "追问：Martin Campbell来自哪里？\n",
    "中间答案：新西兰。\n",
    "所以最终答案是：不是\n",
    "\"\"\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a722158-fc50-4d34-827e-224e9f6e5e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 谁活得更久，穆罕默德·阿里还是艾伦·图灵？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：穆罕默德·阿里去世时多大了？\n",
      "中间答案：穆罕默德·阿里去世时74岁。\n",
      "追问：艾伦·图灵去世时多大了？\n",
      "中间答案：艾伦·图灵去世时41岁。\n",
      "所以最终答案是：穆罕默德·阿里\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answer\"],\n",
    "    template=\"Question: {question}\\n{answer}\"\n",
    ")\n",
    "\n",
    "# **examples[0] 是将examples[0] 字典的键值对（question-answer）解包并传递给format，作为函数参数\n",
    "print(example_prompt.format(**examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4b8892e-c8a8-4c58-89be-5e331f040a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question', 'answer'] output_parser=None partial_variables={} template='Question: {question}\\n{answer}' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "print(example_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a053e2-c8e0-4cd8-9648-01a00057d1b5",
   "metadata": {},
   "source": [
    "#### 关于解包的示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32806357-32c4-4e1c-ad6c-8b664bbf3004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 谁活得更久，穆罕默德·阿里还是艾伦·图灵？\n",
      "Answer: \n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：穆罕默德·阿里去世时多大了？\n",
      "中间答案：穆罕默德·阿里去世时74岁。\n",
      "追问：艾伦·图灵去世时多大了？\n",
      "中间答案：艾伦·图灵去世时41岁。\n",
      "所以最终答案是：穆罕默德·阿里\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_info(question, answer):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "\n",
    "print_info(**examples[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cc0de-1065-4997-ad78-b3ad4325585c",
   "metadata": {},
   "source": [
    "### 生成 Few-shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab9d0a1c-ca67-4b97-9095-011102c06046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 谁活得更久，穆罕默德·阿里还是艾伦·图灵？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：穆罕默德·阿里去世时多大了？\n",
      "中间答案：穆罕默德·阿里去世时74岁。\n",
      "追问：艾伦·图灵去世时多大了？\n",
      "中间答案：艾伦·图灵去世时41岁。\n",
      "所以最终答案是：穆罕默德·阿里\n",
      "\n",
      "\n",
      "Question: craigslist的创始人是什么时候出生的？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：谁是craigslist的创始人？\n",
      "中间答案：Craigslist是由Craig Newmark创办的。\n",
      "追问：Craig Newmark是什么时候出生的？\n",
      "中间答案：Craig Newmark出生于1952年12月6日。\n",
      "所以最终答案是：1952年12月6日\n",
      "\n",
      "\n",
      "Question: 乔治·华盛顿的外祖父是谁？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：谁是乔治·华盛顿的母亲？\n",
      "中间答案：乔治·华盛顿的母亲是Mary Ball Washington。\n",
      "追问：Mary Ball Washington的父亲是谁？\n",
      "中间答案：Mary Ball Washington的父亲是Joseph Ball。\n",
      "所以最终答案是：Joseph Ball\n",
      "\n",
      "\n",
      "Question: 《大白鲨》和《皇家赌场》的导演是同一个国家的吗？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：谁是《大白鲨》的导演？\n",
      "中间答案：《大白鲨》的导演是Steven Spielberg。\n",
      "追问：Steven Spielberg来自哪里？\n",
      "中间答案：美国。\n",
      "追问：谁是《皇家赌场》的导演？\n",
      "中间答案：《皇家赌场》的导演是Martin Campbell。\n",
      "追问：Martin Campbell来自哪里？\n",
      "中间答案：新西兰。\n",
      "所以最终答案是：不是\n",
      "\n",
      "\n",
      "Question: 玛丽·波尔·华盛顿的父亲是谁?\n"
     ]
    }
   ],
   "source": [
    "# 导入 FewShotPromptTemplate 类\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "# 创建一个 FewShotPromptTemplate 对象\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,           # 使用前面定义的 examples 作为范例\n",
    "    example_prompt=example_prompt, # 使用前面定义的 example_prompt 作为提示模板\n",
    "    suffix=\"Question: {input}\",    # 后缀模板，其中 {input} 会被替换为实际输入\n",
    "    input_variables=[\"input\"]     # 定义输入变量的列表\n",
    ")\n",
    "\n",
    "# 使用给定的输入格式化 prompt，并打印结果\n",
    "# 这里的 {input} 将被 \"玛丽·波尔·华盛顿的父亲是谁?\" 替换\n",
    "print(few_shot_prompt.format(input=\"玛丽·波尔·华盛顿的父亲是谁?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559cecd-ad58-495e-92ff-765233888ad8",
   "metadata": {},
   "source": [
    "## 示例选择器 Example Selectors\n",
    "\n",
    "**如果你有大量的参考示例，就得选择哪些要包含在提示中。最好还是根据某种条件或者规则来自动选择，Example Selector 是负责这个任务的类。**\n",
    "\n",
    "BaseExampleSelector 定义如下：\n",
    "\n",
    "```python\n",
    "class BaseExampleSelector(ABC):\n",
    "    \"\"\"用于选择包含在提示中的示例的接口。\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def select_examples(self, input_variables: Dict[str, str]) -> List[dict]:\n",
    "        \"\"\"根据输入选择要使用的示例。\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "`ABC` 是 Python 中的 `abc` 模块中的一个缩写，它表示 \"Abstract Base Class\"（抽象基类）。在 Python 中，抽象基类用于定义其他类必须遵循的基本接口或蓝图，但不能直接实例化。其主要目的是为了提供一种形式化的方式来定义和检查子类的接口。\n",
    "\n",
    "使用抽象基类的几点关键信息：\n",
    "\n",
    "1. **抽象方法**：在抽象基类中，你可以定义抽象方法，它没有实现（也就是说，它没有方法体）。任何继承该抽象基类的子类都必须提供这些抽象方法的实现。\n",
    "\n",
    "2. **不能直接实例化**：你不能直接创建抽象基类的实例。试图这样做会引发错误。它们的主要目的是为了被继承，并在子类中实现其方法。\n",
    "\n",
    "3. **强制子类实现**：如果子类没有实现所有的抽象方法，那么试图实例化该子类也会引发错误。这确保了继承抽象基类的所有子类都遵循了预定的接口。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "627b028b-3762-4b3d-99ca-98c88b175677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in c:\\python311\\lib\\site-packages (0.4.5)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\python311\\lib\\site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.9 in c:\\python311\\lib\\site-packages (from chromadb) (1.10.12)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.2 in c:\\python311\\lib\\site-packages (from chromadb) (0.7.2)\n",
      "Requirement already satisfied: fastapi<0.100.0,>=0.95.2 in c:\\python311\\lib\\site-packages (from chromadb) (0.99.1)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\python311\\lib\\site-packages (from chromadb) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\python311\\lib\\site-packages (from chromadb) (1.25.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\python311\\lib\\site-packages (from chromadb) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\python311\\lib\\site-packages (from chromadb) (4.7.1)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\python311\\lib\\site-packages (from chromadb) (3.2.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\python311\\lib\\site-packages (from chromadb) (1.15.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\python311\\lib\\site-packages (from chromadb) (0.13.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\python311\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\python311\\lib\\site-packages (from chromadb) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\python311\\lib\\site-packages (from chromadb) (7.3.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\python311\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\python311\\lib\\site-packages (from fastapi<0.100.0,>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: packaging in c:\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
      "Requirement already satisfied: protobuf in c:\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.24.0)\n",
      "Requirement already satisfied: sympy in c:\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\python311\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\python311\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\python311\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: certifi in c:\\python311\\lib\\site-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests>=2.28->chromadb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm>=4.65.0->chromadb) (0.4.6)\n",
      "Requirement already satisfied: click>=7.0 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.6)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\python311\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.7.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\python311\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python311\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python311\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\python311\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8886dad-54b9-4fdf-8481-8abdd506676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的模块和类\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "#from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "# 定义一个提示模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],     # 输入变量的名字\n",
    "    template=\"Input: {input}\\nOutput: {output}\",  # 实际的模板字符串\n",
    ")\n",
    "\n",
    "# 这是一个假设的任务示例列表，用于创建反义词\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e15785f7-fa11-4b2b-a668-9838b14839ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m embedding \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings(\n\u001b[0;32m      3\u001b[0m     deployment_name\u001b[38;5;241m=\u001b[39mdeployment_name\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 从给定的示例中创建一个语义相似性选择器\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m example_selector \u001b[38;5;241m=\u001b[39m \u001b[43mSemanticSimilarityExampleSelector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                          \u001b[49m\u001b[38;5;66;43;03m# 可供选择的示例列表\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# 用于生成嵌入向量的嵌入类，用于衡量语义相似性\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mChroma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m# 用于存储嵌入向量并进行相似性搜索的 VectorStore 类\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# 要生成的示例数量\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 创建一个 FewShotPromptTemplate 对象\u001b[39;00m\n\u001b[0;32m     16\u001b[0m similar_prompt \u001b[38;5;241m=\u001b[39m FewShotPromptTemplate(\n\u001b[0;32m     17\u001b[0m     example_selector\u001b[38;5;241m=\u001b[39mexample_selector,  \u001b[38;5;66;03m# 提供一个 ExampleSelector 替代示例\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     example_prompt\u001b[38;5;241m=\u001b[39mexample_prompt,      \u001b[38;5;66;03m# 前面定义的提示模板\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madjective\u001b[39m\u001b[38;5;124m\"\u001b[39m],           \u001b[38;5;66;03m# 输入变量的名字\u001b[39;00m\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\langchain\\prompts\\example_selector\\semantic_similarity.py:96\u001b[0m, in \u001b[0;36mSemanticSimilarityExampleSelector.from_examples\u001b[1;34m(cls, examples, embeddings, vectorstore_cls, k, input_keys, **vectorstore_cls_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     string_examples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sorted_values(eg)) \u001b[38;5;28;01mfor\u001b[39;00m eg \u001b[38;5;129;01min\u001b[39;00m examples]\n\u001b[1;32m---> 96\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvectorstore_cls_kwargs\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(vectorstore\u001b[38;5;241m=\u001b[39mvectorstore, k\u001b[38;5;241m=\u001b[39mk, input_keys\u001b[38;5;241m=\u001b[39minput_keys)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:577\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03mIf a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;124;03m    Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    569\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    570\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39membedding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    576\u001b[0m )\n\u001b[1;32m--> 577\u001b[0m \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:187\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    191\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\langchain\\embeddings\\openai.py:478\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m--> 478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployment\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\langchain\\embeddings\\openai.py:364\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    361\u001b[0m     _iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tokens), _chunk_size)\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 364\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43membed_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     batched_embeddings\u001b[38;5;241m.\u001b[39mextend(r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    371\u001b[0m results: List[List[List[\u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(texts))]\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\langchain\\embeddings\\openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     response \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check_response(response)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_embed_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\langchain\\embeddings\\openai.py:104\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 104\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check_response(response)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;66;03m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again."
     ]
    }
   ],
   "source": [
    "#embedding setup deployment \n",
    "embedding = OpenAIEmbeddings(\n",
    "    deployment_name=deployment_name\n",
    ")\n",
    "\n",
    "\n",
    "# 从给定的示例中创建一个语义相似性选择器\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,                          # 可供选择的示例列表\n",
    "    embedding,                # 用于生成嵌入向量的嵌入类，用于衡量语义相似性\n",
    "    Chroma,                            # 用于存储嵌入向量并进行相似性搜索的 VectorStore 类\n",
    "    k=1                                # 要生成的示例数量\n",
    ")\n",
    "\n",
    "# 创建一个 FewShotPromptTemplate 对象\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # 提供一个 ExampleSelector 替代示例\n",
    "    example_prompt=example_prompt,      # 前面定义的提示模板\n",
    "    prefix=\"Give the antonym of every input\", # 前缀模板\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",     # 后缀模板\n",
    "    input_variables=[\"adjective\"],           # 输入变量的名字\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24dd07-c3fc-4c85-9481-a6d163723b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入是一种感受，所以应该选择 happy/sad 的示例。\n",
    "print(similar_prompt.format(adjective=\"worried\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a113f-0719-4534-8932-1a363991da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入是一种度量，所以应该选择 tall/short的示例。\n",
    "print(similar_prompt.format(adjective=\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760abbb9-c00c-43fb-8c73-341c3993f720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
